import os
import sys
import json
import shutil
from google import genai
# from IPython.display import display, Markdown # .pyãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã¯å‰Šé™¤

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from agents.agent_03_generation import generate_single_page_html
from agents.agent_04_improvement import (
    analyze_article_structure,
    generate_article_purpose,
    select_priority_section_by_data,
    generate_priority_article_titles
)
from utils.file_utils import (
    get_existing_article_count,
    integrate_content_data,
    save_to_markdown,
    load_markdown_table_to_list
)
from utils.analysis_utils import create_placeholder_data

# --- 0. è¨­å®š ---
BASE_DIR = "docs"
REPORTS_DIR = "output_reports"
REPORT_FILE = os.path.join(REPORTS_DIR, "planned_articles.md")
DEFAULT_ARTICLE_COUNT = 3

def setup_client():
    """Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
    try:
        from google.colab import userdata
        GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')
        if not GOOGLE_API_KEY:
            raise ValueError("GEMINI_API_KEY ãŒ Colab Secrets ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return genai.Client(api_key=GOOGLE_API_KEY)
    except ImportError:
        GOOGLE_API_KEY = os.environ.get('GEMINI_API_KEY')
        if not GOOGLE_API_KEY:
            raise EnvironmentError("GEMINI_API_KEY ãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return genai.Client(api_key=GOOGLE_API_KEY)
    except Exception as e:
        print(f"âŒ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def load_corporate_identity():
    """
    'main_01' ãŒä¿å­˜ã—ãŸæ³•äººæ ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚
    """
    identity_file = os.path.join(REPORTS_DIR, "01_corporate_identity.md")
    try:
        with open(identity_file, 'r', encoding='utf-8') as f:
            identity = f.read()
        print(f"âœ… æ³•äººæ ¼ã‚’ {identity_file} ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
        return identity
    except Exception as e:
        print(f"âŒ æ³•äººæ ¼ãƒ•ã‚¡ã‚¤ãƒ« ({identity_file}) ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        # (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
        try:
            from agents.agent_01_identity import generate_corporate_identity
            with open("config/opinion.txt", 'r', encoding='utf-8') as f:
                RAW_VISION_INPUT = f.read()
            client = setup_client()
            if client:
                return generate_corporate_identity(client, RAW_VISION_INPUT)
            else:
                raise Exception("ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—")
        except Exception as e_fallback:
            print(f"âŒ ä»£æ›¿å‡¦ç†ã‚‚å¤±æ•—: {e_fallback}ã€‚ãƒ€ãƒŸãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return "ãƒ‘ãƒ¼ãƒ‘ã‚¹: ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹å€‹äººã®ç”Ÿæ´»æœ€é©åŒ–ã€‚ ãƒˆãƒ¼ãƒ³: è«–ç†çš„ã€å…ˆé€²çš„ã€‚"

def main():
    print(f"--- ğŸ”„ HPæ”¹å–„ã‚µã‚¤ã‚¯ãƒ« (ãƒ•ã‚§ãƒ¼ã‚º5-8) [åˆ†æãƒ»æ–°è¦ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰] é–‹å§‹ ---")

    # --- 0. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– ---
    gemini_client = setup_client()
    if gemini_client is None: sys.exit(1)

    # --- (å‰æ) æ³•äººæ ¼ã®å–å¾— ---
    CORPORATE_IDENTITY = load_corporate_identity()

    # --- 5a. æˆ¦ç•¥ï¼ˆAS-ISåˆ†æï¼‰---
    print(f"\n--- [ãƒ•ã‚§ãƒ¼ã‚º5a: AS-ISåˆ†æ] è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ« ({REPORT_FILE}) ã‚’èª­ã¿è¾¼ã¿ä¸­ ---")
    processed_articles = None
    if os.path.exists(REPORT_FILE):
        # â¬‡ï¸ [ä¿®æ­£] 'summary' ã‚­ãƒ¼ã§èª­ã¿è¾¼ã¾ã‚Œã‚‹
        processed_articles = load_markdown_table_to_list(REPORT_FILE)

    if processed_articles:
        print(f"âœ… æ—¢å­˜ã®è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ {len(processed_articles)} ä»¶ã®ç›®çš„ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ï¼ˆAPIã‚³ãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰")
    else:
        # (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
        print(f"âš ï¸ è¨ˆç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        print(f"--- [ãƒ•ã‚§ãƒ¼ã‚º5a ä»£æ›¿] æ—¢å­˜ã‚µã‚¤ãƒˆ ({BASE_DIR}) ã‚’ã‚¹ã‚­ãƒ£ãƒ³ä¸­ ---")
        processed_articles = []
        TARGET_EXTENSIONS = ('.html', '.htm')
        if not os.path.isdir(BASE_DIR):
            print(f"âŒ åˆ†æå¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {BASE_DIR} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            sys.exit(1)
        for root, _, files in os.walk(BASE_DIR):
            for filename in files:
                if filename.lower().endswith(TARGET_EXTENSIONS):
                    full_path = os.path.join(root, filename)
                    article_data, error = analyze_article_structure(full_path)
                    if article_data:
                        purpose = generate_article_purpose(gemini_client, article_data, CORPORATE_IDENTITY)
                        processed_articles.append({
                            "file_name": os.path.relpath(full_path, BASE_DIR).replace(os.path.sep, '/'),
                            "title": article_data['page_title'],
                            "summary": purpose # â¬…ï¸ [ä¿®æ­£] 'summary' ã‚­ãƒ¼ã§ä¿å­˜
                        })
        print(f"\nâœ… [ãƒ•ã‚§ãƒ¼ã‚º5a ä»£æ›¿å®Œäº†] åˆè¨ˆ {len(processed_articles)} ä»¶ã®ç›®çš„ã‚’APIã§å†å®šç¾©ã—ã¾ã—ãŸã€‚")

    # --- 5b. æˆ¦ç•¥çš„å„ªå…ˆåº¦ã®æ±ºå®š ---
    print("\n--- [ãƒ•ã‚§ãƒ¼ã‚º5b: æˆ¦ç•¥çš„å„ªå…ˆåº¦ã®æ±ºå®š] AIãŒåˆ†æä¸­ ---")
    df_all_data = create_placeholder_data(processed_articles)
    # â¬‡ï¸ [ä¿®æ­£] 'summary' ã‚­ãƒ¼ã‚’æŒã¤ãƒªã‚¹ãƒˆã‚’æ¸¡ã™
    priority_result = select_priority_section_by_data(gemini_client, df_all_data, CORPORATE_IDENTITY, processed_articles)

    priority_file = priority_result['file_name']
    priority_section_info = next(p for p in processed_articles if p['file_name'] == priority_file)

    print(f"âœ… [ãƒ•ã‚§ãƒ¼ã‚º5b å®Œäº†] æœ€å„ªå…ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒæ±ºå®šã—ã¾ã—ãŸã€‚")
    print(f"ğŸ¥‡ æœ€å„ªå…ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³: {priority_section_info['title']} (`{priority_file}`)")
    print(f"ğŸ”‘ é¸å®šç†ç”±: {priority_result['reason']}")

    # --- 6. è©³ç´°è¨˜äº‹ã®ä¼ç”» ---
    print("\n--- [ãƒ•ã‚§ãƒ¼ã‚º6: è©³ç´°è¨˜äº‹ã®ä¼ç”»] AIãŒä¼ç”»ä¸­ ---")
    start_number = get_existing_article_count(BASE_DIR) + 1
    # â¬‡ï¸ [ä¿®æ­£] 'summary' ã‚­ãƒ¼ã‚’æŒã¤è¾æ›¸ã‚’æ¸¡ã™
    error_msg, article_plans = generate_priority_article_titles(
        gemini_client, priority_section_info, CORPORATE_IDENTITY, DEFAULT_ARTICLE_COUNT, start_number
    )

    if not article_plans:
        print(f"âŒ è¨˜äº‹ã®ä¼ç”»ã«å¤±æ•—ã—ã¾ã—ãŸ: {error_msg}")
        sys.exit(1)

    print(f"âœ… [ãƒ•ã‚§ãƒ¼ã‚º6 å®Œäº†] {len(article_plans)} ä»¶ã®æ–°è¦è¨˜äº‹ã‚’ä¼ç”»ã—ã¾ã—ãŸã€‚")

    # --- 7. (æœ¬ç•ª) è©³ç´°è¨˜äº‹ã®HTMLç”Ÿæˆ ---
    print("\n--- [ãƒ•ã‚§ãƒ¼ã‚º7: è©³ç´°è¨˜äº‹ã®HTMLç”Ÿæˆ] ---")

    new_article_files_generated = []

    for i, plan in enumerate(article_plans):
        target_dir = os.path.dirname(priority_section_info['file_name'])
        file_name = os.path.join(target_dir, plan.get('file_name', f'error-slug-{i}.html'))
        file_name = file_name.replace(os.path.sep, '/')

        article_plans[i]['file_name'] = file_name

        print(f"\n--- ğŸ­ [æœ¬ç•ªç”Ÿæˆ] {plan['title']} ---")

        target_page_for_generation = {
            'title': plan['title'],
            'file_name': file_name,
            'purpose': plan['summary']
        }

        nav_list_for_generation = [
            {
                "file_name": p['file_name'],
                "title": p['title'],
                "purpose": p.get('summary', p.get('generated_purpose', '')) # â¬…ï¸ [ä¿®æ­£] 'summary' å„ªå…ˆ
            } for p in processed_articles
        ]

        final_html_code = generate_single_page_html(
            gemini_client,
            target_page_for_generation,
            CORPORATE_IDENTITY,
            None,
            nav_list_for_generation,
            retry_attempts=3
        )

        if "âŒ" not in final_html_code:
            generate_file_path = os.path.join(BASE_DIR, file_name)
            os.makedirs(os.path.dirname(generate_file_path), exist_ok=True)
            try:
                with open(generate_file_path, 'w', encoding='utf-8') as f:
                    f.write(final_html_code)
                print(f"âœ… [æœ¬ç•ªç”Ÿæˆ] ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆæˆåŠŸ: {generate_file_path}")
                new_article_files_generated.append(plan)
            except Exception as e:
                print(f"âŒ [æœ¬ç•ªç”Ÿæˆ] ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¤±æ•—: {e}")
        else:
             print(f"âŒ [æœ¬ç•ªç”Ÿæˆ] HTMLã‚³ãƒ¼ãƒ‰ç”Ÿæˆå¤±æ•—: {file_name}")

    # --- 8. ãƒãƒ–ãƒšãƒ¼ã‚¸ã®è‡ªå‹•æ›´æ–° ---
    print(f"\n--- [ãƒ•ã‚§ãƒ¼ã‚º8: ãƒãƒ–ãƒšãƒ¼ã‚¸ã®è‡ªå‹•æ›´æ–°] ---")

    all_content_plans = integrate_content_data(processed_articles, article_plans)

    hub_path_to_update = priority_file
    hub_dir = os.path.dirname(hub_path_to_update)

    print(f"ğŸ­ {hub_path_to_update} ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã€é…ä¸‹ã®å…¨è¨˜äº‹ãƒªãƒ³ã‚¯ã‚’çµ„ã¿è¾¼ã¿ã¾ã™ã€‚")

    try:
        parent_page_info = next(p for p in all_content_plans if p['file_name'] == hub_path_to_update)
    except StopIteration:
        print(f"âŒ [ãƒãƒ–æ›´æ–°å¤±æ•—] è¨ˆç”»ãƒªã‚¹ãƒˆã«è¦ªãƒãƒ– ({hub_path_to_update}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        sys.exit(1)

    parent_page_info_for_regeneration = {
        'file_name': parent_page_info['file_name'],
        'title': parent_page_info['title'],
        'purpose': parent_page_info.get('summary', parent_page_info.get('generated_purpose')) # â¬…ï¸ [ä¿®æ­£] 'summary' å„ªå…ˆ
    }

    all_articles_in_section = []
    for plan in all_content_plans:
         if (os.path.dirname(plan['file_name']) == hub_dir) and \
            (plan['file_name'] != hub_path_to_update):
            all_articles_in_section.append(plan)

    print(f"  -> {len(all_articles_in_section)} ä»¶ã®è©³ç´°è¨˜äº‹ï¼ˆæ–°æ—§å«ã‚€ï¼‰ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¾ã—ãŸã€‚")

    new_article_links_html = "<ul>"
    if not all_articles_in_section:
        new_article_links_html = "<p>ï¼ˆç¾åœ¨ã€ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°è¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰</p>"
    else:
        for plan in all_articles_in_section:
            link_path = os.path.basename(plan['file_name'])
            article_summary = plan.get('summary', plan.get('generated_purpose', '')) # â¬…ï¸ [ä¿®æ­£] 'summary' å„ªå…ˆ
            new_article_links_html += f"<li><a href='{link_path}' class='text-blue-500 hover:underline'>{plan['title']}</a>: {article_summary}</li>"
        new_article_links_html += "</ul>"

    parent_page_info_for_regeneration['purpose'] = f"""
    ã“ã®ãƒšãƒ¼ã‚¸ï¼ˆ{parent_page_info_for_regeneration['title']}ï¼‰ã¯ã€ä»¥ä¸‹ã®ã€Œ{len(all_articles_in_section)}ä»¶ã®å…¨è©³ç´°è¨˜äº‹ã€ã¸ã®å°ç·šã‚’å«ã‚€ãƒãƒ–ãƒšãƒ¼ã‚¸ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚
    å…ƒã®ç›®çš„ï¼ˆ{parent_page_info_for_regeneration['purpose']}ï¼‰ã‚’è¦ç´„ã—ã¤ã¤ã€ã“ã‚Œã‚‰ã®æ–°ã—ã„è¨˜äº‹ã¸ã®æ˜ç¢ºãªå°ç·šï¼ˆç›®æ¬¡ï¼‰ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

    ã€{hub_dir} ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å…¨è©³ç´°è¨˜äº‹ãƒªã‚¹ãƒˆã€‘
    {new_article_links_html}
    """

    nav_list_for_generation = [
        {
            "file_name": p['file_name'],
            "title": p['title'],
            "purpose": p.get('summary', p.get('generated_purpose', '')) # â¬…ï¸ [ä¿®æ­£] 'summary' å„ªå…ˆ
        } for p in all_content_plans
    ]

    final_hub_code = generate_single_page_html(
        gemini_client,
        parent_page_info_for_regeneration,
        CORPORATE_IDENTITY,
        None,
        nav_list_for_generation,
        retry_attempts=3
    )

    if "âŒ" not in final_hub_code:
        hub_file_path = os.path.join(BASE_DIR, parent_page_info_for_regeneration['file_name'])
        try:
            with open(hub_file_path, "w", encoding="utf-8") as f:
                f.write(final_hub_code)
            print(f"âœ… [ãƒãƒ–æ›´æ–°å®Œäº†] ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãä¿å­˜ã—ã¾ã—ãŸ: {hub_file_path}")
        except Exception as e:
            print(f"âŒ [ãƒãƒ–æ›´æ–°å¤±æ•—] ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print(f"âŒ [ãƒãƒ–æ›´æ–°å¤±æ•—] HTMLã®å†ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    # --- 9. (ãƒ¬ãƒãƒ¼ãƒˆ) å…¨ä½“è¨ˆç”»ã‚’MDãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ ---
    print("\n--- [æœ€çµ‚å‡¦ç†: å…¨ä½“è¨ˆç”»ã®ä¿å­˜] ---")
    os.makedirs(REPORTS_DIR, exist_ok=True)

    save_to_markdown(all_content_plans, REPORT_FILE)

    print(f"âœ… å…¨ä½“è¨ˆç”»ã‚’ {REPORT_FILE} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    print("--- ğŸ”„ HPæ”¹å–„ã‚µã‚¤ã‚¯ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ å®Œäº† ---")

if __name__ == "__main__":
    main()
